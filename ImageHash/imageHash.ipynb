{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596687294920",
   "display_name": "Python 3.7.6 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First gather.py then index.py, then search.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are we going to do?\n",
    "\n",
    "We are going to utilize image fingerprinting to perform near-duplicate image detection. This technique is commonly called “perceptual image hashing” or simply “image hashing”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is image fingerprinting/hashing?\n",
    "\n",
    "Image hashing is the process of examining the contents of an image and then constructing a value that uniquely identifies an image based on these contents.\n",
    "\n",
    "For example, take a look at the image at the top of this post. Given an input image, we are going apply a hash function and compute an “image hash” based on the image’s visual appearance. Images that are “similar” should have hashes that are “similar” as well”. Using image hashing algorithms makes performing near-duplicate image detection substantially easier.\n",
    "\n",
    "In particular, we’ll be using the “difference hash”, or simply dHash algorithm to compute our image fingerprints. Simply put, the dHash algorithm looks at the difference between adjacent pixel values. Then, based on these differences, a hash value is created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why can’t we use md5, sha-1, etc.?\n",
    "\n",
    "Unfortunately, we cannot use cryptographic hashing algorithms in our implementation. Due to the nature of cryptographic hashing algorithms, very tiny changes in the input file will result in a substantially different hash. In the case of image fingerprinting, we actually want our similar inputs to have similar output hashes as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply put, you can use image fingerprinting/hashing in nearly any setting where you are concerned with detecting near-duplicate copies of an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among computer vision researchers, the CALTECH-101 dataset is legendary. It contains over 7,500 images from 101 different categories, including people, motorcycles, and airplanes.\n",
    "\n",
    "From these ~7,500 images, I have randomly selected 17 of them.\n",
    "\n",
    "Then, from these 17 randomly selected images, I have created N new images by randomly resizing them by +/- a few percentage points. Our goal here is to find these near-duplicate images — kind of like finding a needle in a haystack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, these images are identical in every way, except for width and height. And since they do not have the same dimensions, we cannot rely on simple md5 checksums. And more importantly, images with similar content may have dramatically different md5 hashes. Instead, we can resort to image hashing, where images with similar content will also have similar hash fingerprints.\n",
    "\n",
    "So let’s get started by writing the code to fingerprint our dataset. Open up a new file, name it index.py, and let’s get to work:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we’ll do is import the packages we’ll need. We’ll use the Image class from PIL or Pillow to load our images off disk. Then the imagehash library can be utilized to construct the perceptual hash.\n",
    "\n",
    "From there, argparse is used to parse command line arguments, shelve is used as a simple key-value database (Python dictionary) residing on disk, and glob is utilized to easily gather the paths to our images.\n",
    "\n",
    "We then parse our command line arguments. The first, --dataset is the path to our input directory of images. The second, --shelve is the output path to our shelve database.\n",
    "\n",
    "Next, we open our shelve database for writing. This db will store our image hashes. More on that next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = imagePath[imagePath.rfind(\"/\") + 1:]\n",
    "db[h] = db.get(h, []) + [filename]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like I mentioned earlier in this post, images with the same fingerprint are considered to be identical.\n",
    "\n",
    "Thus, if our goal is to find near-identical images, we need to maintain a list of images that have the same fingerprint value.\n",
    "\n",
    "And that’s exactly what those lines do.\n",
    "\n",
    "The former extracts the filename of the image. And then the latter maintains a list of filenames that have the same image hash.\n",
    "\n",
    "To extract image fingerprints from our dataset and build our database of hashes, issue the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script will run for a few seconds and once it is done, you’ll have a file named db.shelve that contains the key-value pairs of image fingerprints and filenames.\n",
    "\n",
    "This same basic algorithm is what I utilized years ago when I was working for the dating startup. We took our dataset of inappropriate images, constructed an image fingerprint for each image, and then stored them in our database. When a new image arrived, I simply computed the hash of the image and checked to database to see if the upload had already been flagged for invalid content.\n",
    "\n",
    "In the next step I’ll show you how to perform the actual search to determine if an image already exists in the database with the same hash value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Searching a Dataset\n",
    "\n",
    "Now that we have built a database of image fingerprints, it’s time to search our dataset.\n",
    "\n",
    "Open up a new file, name it search.py, and we’ll get coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we’ll import our relevant packages on. We then parse our command line arguments on. We’ll need three switches, –dataset, which is the path to our original dataset of images, –shelve, the path to where our shelve database of key-value pairs resides, and –query, the path to our query/uploaded image. Our goal will be to take the query image and determine if it already exists in our database.\n",
    "\n",
    "Now, let’s write the code to perform the actual search:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first open our database, and then we load our image off of disk, compute the image fingerprint, and find all images with the same fingerprint value.\n",
    "\n",
    "If there are any images with the same hash value, we loop over these images and display them to our screen.\n",
    "\n",
    "Using this code we will be able to determine if an image already exists in our database using nothing but the fingerprint value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}