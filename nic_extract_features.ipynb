{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using VGG16 model to extract features of a image and fine tuning VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from pickle import dump\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "#R_LOSS_FACTOR = 10000\n",
    "#import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_FOLDER='/home/pytorch_ashish/deep_learning/data/alt_text_data_all/models/NIC_model/'\n",
    "new_model = load_model(\"/home/pytorch_ashish/deep_learning/data/alt_text_data_all/models/NIC_model/val_acc_9280_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6e-07"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate=K.eval(new_model.optimizer.lr)\n",
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataframe=pd.read_csv('/home/pytorch_ashish/deep_learning/data/alt_text_data_all/image_location_venky.csv')\n",
    "cengage= pd.read_csv('/home/pytorch_ashish/deep_learning/data/alt_text_data_all/cengage_production_data.csv')\n",
    "pearson= pd.read_csv('/home/pytorch_ashish/deep_learning/data/alt_text_data_all/pearson_production_data.csv')\n",
    "wiley=pd.read_csv('/home/pytorch_ashish/deep_learning/data/alt_text_data_all/wiley_production_data.csv')\n",
    "wiley.rename(columns={'image_names':'Name'}, inplace=True)\n",
    "pearson.rename(columns={'image_names':'Name'}, inplace=True)\n",
    "cengage.rename(columns={'image_names':'Name'}, inplace=True)\n",
    "\n",
    "image_dataframe=pd.merge(image_dataframe, cengage, on='Name', how='left')\n",
    "image_dataframe.drop(['image_path', 'alt_text_html', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "image_dataframe=pd.merge(image_dataframe, pearson, on='Name', how='left')\n",
    "image_dataframe[\"alt_text\"] = image_dataframe[\"alt_text_x\"].astype(str) + \" \"+image_dataframe[\"alt_text_y\"].astype(str)\n",
    "image_dataframe['subject_area'] = image_dataframe['subject_area_x'].astype(str) + \" \"+ image_dataframe['subject_area_y'].astype(str)\n",
    "image_dataframe.drop(['alt_text_x', \"alt_text_y\", 'subject_area_x', 'subject_area_y', 'alt_text_html', 'image_path'], axis=1, inplace=True)\n",
    "\n",
    "image_dataframe=pd.merge(image_dataframe, wiley, on='Name', how='left')\n",
    "image_dataframe[\"alt_text\"] = image_dataframe[\"alt_text_x\"].astype(str) + \" \"+ image_dataframe[\"alt_text_y\"].astype(str)\n",
    "image_dataframe['subject_area'] = image_dataframe['subject_area_x'].astype(str) + \" \"+ image_dataframe['subject_area_y'].astype(str)\n",
    "image_dataframe.drop(['alt_text_x', \"alt_text_y\", 'subject_area_x', 'subject_area_y', 'alt_text_html', 'image_path'], axis=1, inplace=True)\n",
    "\n",
    "banned = ['nan']\n",
    "f = lambda x: ' '.join([item for item in x.split() if item not in banned])\n",
    "image_dataframe[\"subject_area\"] = image_dataframe[\"subject_area\"].apply(f)\n",
    "image_dataframe[\"alt_text\"] = image_dataframe[\"alt_text\"].apply(f)\n",
    "image_dataframe = image_dataframe[image_dataframe.subject_area != '']\n",
    "image_dataframe.subject_area=image_dataframe.subject_area.replace({\"other other\": \"others\", \"other\": \"others\"})\n",
    "image_dataframe.reset_index(drop=True, inplace=True)\n",
    "\n",
    "include = ['maths', 'science', 'others', 'emss', 'canada', 'engineering', 'business', 'history']\n",
    "indexNames=[]\n",
    "for i in range(image_dataframe.shape[0]):\n",
    "    if(image_dataframe.loc[i]['subject_area'] not in include):\n",
    "        indexNames.append(i)\n",
    "image_dataframe.drop(labels=indexNames, inplace=True)\n",
    "image_dataframe.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maths          146839\n",
       "science         10820\n",
       "others           5116\n",
       "emss             3602\n",
       "canada           2852\n",
       "engineering      1854\n",
       "business         1681\n",
       "history          1014\n",
       "Name: subject_area, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe['subject_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['maths', 'history', 'science', 'engineering', 'business', 'others',\n",
       "       'emss', 'canada'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe.subject_area.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name            0\n",
       "Path            0\n",
       "Height          0\n",
       "Width           0\n",
       "alt_text        0\n",
       "subject_area    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173778, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Path</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>alt_text</th>\n",
       "      <th>subject_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9781337111348_11348_ch02_2.1_017-t2.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>131</td>\n",
       "      <td>181</td>\n",
       "      <td>The image consists of a Minitab output. Visual...</td>\n",
       "      <td>maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9781285194790_9781285194790-551-t2.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>550</td>\n",
       "      <td>593</td>\n",
       "      <td>A map shows the Second Iraq War. Majority popu...</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9781133947257_9781133947257_ch01_65-t2.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>101</td>\n",
       "      <td>184</td>\n",
       "      <td>In the Sherlock Holmes mystery The Final Solut...</td>\n",
       "      <td>maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781305652231_52231_ch01_f022-t2.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>24</td>\n",
       "      <td>188</td>\n",
       "      <td>The image consists of a number line. The numbe...</td>\n",
       "      <td>maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ceng_image205.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>131</td>\n",
       "      <td>268</td>\n",
       "      <td>The image consists of a visual representation ...</td>\n",
       "      <td>maths</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Name  \\\n",
       "0     9781337111348_11348_ch02_2.1_017-t2.png   \n",
       "1      9781285194790_9781285194790-551-t2.png   \n",
       "2  9781133947257_9781133947257_ch01_65-t2.png   \n",
       "3        9781305652231_52231_ch01_f022-t2.png   \n",
       "4                           ceng_image205.png   \n",
       "\n",
       "                                                Path  Height  Width  \\\n",
       "0  /home/pytorch_ashish/deep_learning/data/alt_te...     131    181   \n",
       "1  /home/pytorch_ashish/deep_learning/data/alt_te...     550    593   \n",
       "2  /home/pytorch_ashish/deep_learning/data/alt_te...     101    184   \n",
       "3  /home/pytorch_ashish/deep_learning/data/alt_te...      24    188   \n",
       "4  /home/pytorch_ashish/deep_learning/data/alt_te...     131    268   \n",
       "\n",
       "                                            alt_text subject_area  \n",
       "0  The image consists of a Minitab output. Visual...        maths  \n",
       "1  A map shows the Second Iraq War. Majority popu...      history  \n",
       "2  In the Sherlock Holmes mystery The Final Solut...        maths  \n",
       "3  The image consists of a number line. The numbe...        maths  \n",
       "4  The image consists of a visual representation ...        maths  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 173778 validated image filenames belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "def gray(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = np.expand_dims(gray_image, axis=-1)\n",
    "    return gray_image\n",
    "BATCH_SIZE=32\n",
    "trdata = ImageDataGenerator(rescale=1./255,  preprocessing_function=gray)\n",
    "traindata = trdata.flow_from_dataframe(dataframe = image_dataframe\n",
    "                                         , directory = None\n",
    "                                         , x_col='Path'\n",
    "                                         , y_col='subject_area'\n",
    "                                         , target_size = (224,224)\n",
    "                                         , batch_size = BATCH_SIZE\n",
    "                                         , shuffle = False\n",
    "                                         #, classes = y_train_en\n",
    "                                         , class_mode = 'categorical'\n",
    "                                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5431"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(round(image_dataframe.shape[0]/BATCH_SIZE ,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5430.5625"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe.shape[0]/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_gen(dataframe):\n",
    "   \n",
    "    final_model = Model(inputs=new_model.inputs, outputs=new_model.layers[-2].output)\n",
    "    # summarize\n",
    "    print(final_model.summary())\n",
    "   \n",
    "    features = []\n",
    "    for i in tqdm(range(int(round(dataframe.shape[0]/BATCH_SIZE ,0)))):\n",
    "    \n",
    "        images, labels = next(traindata)\n",
    "        # get features\n",
    "        feature = final_model.predict(images, verbose=0)\n",
    "        \n",
    "        features.extend(feature)\n",
    "        \n",
    "    features=np.array(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%|          | 0/5431 [00:00<?, ?it/s]Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 119,545,856\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "100%|██████████| 5431/5431 [27:30<00:00,  3.29it/s]\n",
      "Extracted Features: 173778\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "features = extract_features_gen(image_dataframe)\n",
    "print('Extracted Features: %d' % len(features))\n",
    "RUN_FOLDER='/home/pytorch_ashish/deep_learning/data/alt_text_data_all/models/NIC_model/'\n",
    "# save to file\n",
    "dump(features, open(RUN_FOLDER+'features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173778, 4096)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sent):\n",
    "\t\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    sent =sent.replace('x', 'x-axis')\n",
    "    sent=sent.replace('y', 'y-axis')\n",
    "    word_tokens = word_tokenize(sent)\n",
    "    sent = ' '.join(w for w in word_tokens if not w in stop_words and len(w)>2)\n",
    "    sent= re.sub(r\"(\\d+\\s?)+\",\"number \",sent)\n",
    "\n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173778/173778 [09:21<00:00, 309.33it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(image_dataframe.shape[0])):\n",
    "    clean=clean_sentence(image_dataframe.loc[i]['alt_text'])\n",
    "    #print(clean)\n",
    "    image_dataframe['alt_text'][i]='startseq ' + clean + ' endseq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'startseq attributes table underscore code underscore name underscore zip customer dot agent underscore code agent dot agent underscore code agent underscore phone line underscore code underscore name adares underscore zip customer dot agent underscore code number agent dot agent underscore code number agent underscore phone line underscore code underscore name rodriguez underscore zip customer dot agent underscore code number agent dot agent underscore code number agent underscore phone line underscore code underscore name rakowski underscore zip customer dot agent underscore code number agent dot agent underscore code number agent underscore phone line underscore code underscore name walker underscore zip customer dot agent underscore code number agent dot agent underscore code number agent underscore phone line underscore code underscore name vanloo underscore zip customer dot agent underscore code number agent dot agent underscore code number agent underscore phone line underscore code blank underscore name blank underscore zip blank customer dot agent underscore code blank agent dot agent underscore code number agent underscore phone endseq'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image_dataframe['alt_text'][0]=clean\n",
    "image_dataframe['alt_text'][11458]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173778, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = image_dataframe[0:]\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
