{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from pickle import dump\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "#R_LOSS_FACTOR = 10000\n",
    "#import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_FOLDER='/home/pytorch_ashish/deep_learning/data/alt_text_data_all/models/NIC_model/'\n",
    "new_model = load_model(\"/home/pytorch_ashish/deep_learning/data/alt_text_data_all/models/NIC_model/val_acc_9280_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6e-07"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate=K.eval(new_model.optimizer.lr)\n",
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataframe=pd.read_csv('/home/pytorch_ashish/deep_learning/data/alt_text_data_all/image_location_venky.csv')\n",
    "cengage= pd.read_csv('/home/pytorch_ashish/deep_learning/data/alt_text_data_all/cengage_production_data.csv')\n",
    "pearson= pd.read_csv('/home/pytorch_ashish/deep_learning/data/alt_text_data_all/pearson_production_data.csv')\n",
    "wiley=pd.read_csv('/home/pytorch_ashish/deep_learning/data/alt_text_data_all/wiley_production_data.csv')\n",
    "wiley.rename(columns={'image_names':'Name'}, inplace=True)\n",
    "pearson.rename(columns={'image_names':'Name'}, inplace=True)\n",
    "cengage.rename(columns={'image_names':'Name'}, inplace=True)\n",
    "\n",
    "image_dataframe=pd.merge(image_dataframe, cengage, on='Name', how='left')\n",
    "image_dataframe.drop(['image_path', 'alt_text_html', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "image_dataframe=pd.merge(image_dataframe, pearson, on='Name', how='left')\n",
    "image_dataframe[\"alt_text\"] = image_dataframe[\"alt_text_x\"].astype(str) + \" \"+image_dataframe[\"alt_text_y\"].astype(str)\n",
    "image_dataframe['subject_area'] = image_dataframe['subject_area_x'].astype(str) + \" \"+ image_dataframe['subject_area_y'].astype(str)\n",
    "image_dataframe.drop(['alt_text_x', \"alt_text_y\", 'subject_area_x', 'subject_area_y', 'alt_text_html', 'image_path'], axis=1, inplace=True)\n",
    "\n",
    "image_dataframe=pd.merge(image_dataframe, wiley, on='Name', how='left')\n",
    "image_dataframe[\"alt_text\"] = image_dataframe[\"alt_text_x\"].astype(str) + \" \"+ image_dataframe[\"alt_text_y\"].astype(str)\n",
    "image_dataframe['subject_area'] = image_dataframe['subject_area_x'].astype(str) + \" \"+ image_dataframe['subject_area_y'].astype(str)\n",
    "image_dataframe.drop(['alt_text_x', \"alt_text_y\", 'subject_area_x', 'subject_area_y', 'alt_text_html', 'image_path'], axis=1, inplace=True)\n",
    "\n",
    "banned = ['nan']\n",
    "f = lambda x: ' '.join([item for item in x.split() if item not in banned])\n",
    "image_dataframe[\"subject_area\"] = image_dataframe[\"subject_area\"].apply(f)\n",
    "image_dataframe[\"alt_text\"] = image_dataframe[\"alt_text\"].apply(f)\n",
    "image_dataframe = image_dataframe[image_dataframe.subject_area != '']\n",
    "image_dataframe.subject_area=image_dataframe.subject_area.replace({\"other other\": \"others\", \"other\": \"others\"})\n",
    "image_dataframe.reset_index(drop=True, inplace=True)\n",
    "\n",
    "include = ['maths', 'science', 'others', 'emss', 'canada', 'engineering', 'business', 'history']\n",
    "indexNames=[]\n",
    "for i in range(image_dataframe.shape[0]):\n",
    "    if(image_dataframe.loc[i]['subject_area'] not in include):\n",
    "        indexNames.append(i)\n",
    "image_dataframe.drop(labels=indexNames, inplace=True)\n",
    "image_dataframe.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maths          146839\n",
       "science         10820\n",
       "others           5116\n",
       "emss             3602\n",
       "canada           2852\n",
       "engineering      1854\n",
       "business         1681\n",
       "history          1014\n",
       "Name: subject_area, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe['subject_area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['maths', 'history', 'science', 'engineering', 'business', 'others',\n",
       "       'emss', 'canada'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe.subject_area.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name            0\n",
       "Path            0\n",
       "Height          0\n",
       "Width           0\n",
       "alt_text        0\n",
       "subject_area    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173778, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Path</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>alt_text</th>\n",
       "      <th>subject_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9781337111348_11348_ch02_2.1_017-t2.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>131</td>\n",
       "      <td>181</td>\n",
       "      <td>The image consists of a Minitab output. Visual...</td>\n",
       "      <td>maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9781285194790_9781285194790-551-t2.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>550</td>\n",
       "      <td>593</td>\n",
       "      <td>A map shows the Second Iraq War. Majority popu...</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9781133947257_9781133947257_ch01_65-t2.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>101</td>\n",
       "      <td>184</td>\n",
       "      <td>In the Sherlock Holmes mystery The Final Solut...</td>\n",
       "      <td>maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781305652231_52231_ch01_f022-t2.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>24</td>\n",
       "      <td>188</td>\n",
       "      <td>The image consists of a number line. The numbe...</td>\n",
       "      <td>maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ceng_image205.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>131</td>\n",
       "      <td>268</td>\n",
       "      <td>The image consists of a visual representation ...</td>\n",
       "      <td>maths</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Name  \\\n",
       "0     9781337111348_11348_ch02_2.1_017-t2.png   \n",
       "1      9781285194790_9781285194790-551-t2.png   \n",
       "2  9781133947257_9781133947257_ch01_65-t2.png   \n",
       "3        9781305652231_52231_ch01_f022-t2.png   \n",
       "4                           ceng_image205.png   \n",
       "\n",
       "                                                Path  Height  Width  \\\n",
       "0  /home/pytorch_ashish/deep_learning/data/alt_te...     131    181   \n",
       "1  /home/pytorch_ashish/deep_learning/data/alt_te...     550    593   \n",
       "2  /home/pytorch_ashish/deep_learning/data/alt_te...     101    184   \n",
       "3  /home/pytorch_ashish/deep_learning/data/alt_te...      24    188   \n",
       "4  /home/pytorch_ashish/deep_learning/data/alt_te...     131    268   \n",
       "\n",
       "                                            alt_text subject_area  \n",
       "0  The image consists of a Minitab output. Visual...        maths  \n",
       "1  A map shows the Second Iraq War. Majority popu...      history  \n",
       "2  In the Sherlock Holmes mystery The Final Solut...        maths  \n",
       "3  The image consists of a number line. The numbe...        maths  \n",
       "4  The image consists of a visual representation ...        maths  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 173778 validated image filenames belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "def gray(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = np.expand_dims(gray_image, axis=-1)\n",
    "    return gray_image\n",
    "BATCH_SIZE=32\n",
    "trdata = ImageDataGenerator(rescale=1./255,  preprocessing_function=gray)\n",
    "traindata = trdata.flow_from_dataframe(dataframe = image_dataframe\n",
    "                                         , directory = None\n",
    "                                         , x_col='Path'\n",
    "                                         , y_col='subject_area'\n",
    "                                         , target_size = (224,224)\n",
    "                                         , batch_size = BATCH_SIZE\n",
    "                                         , shuffle = False\n",
    "                                         #, classes = y_train_en\n",
    "                                         , class_mode = 'categorical'\n",
    "                                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5431"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(round(image_dataframe.shape[0]/BATCH_SIZE ,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5430.5625"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe.shape[0]/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_gen(dataframe):\n",
    "   \n",
    "    final_model = Model(inputs=new_model.inputs, outputs=new_model.layers[-2].output)\n",
    "    # summarize\n",
    "    print(final_model.summary())\n",
    "   \n",
    "    features = []\n",
    "    for i in tqdm(range(int(round(dataframe.shape[0]/BATCH_SIZE ,0)))):\n",
    "    \n",
    "        images, labels = next(traindata)\n",
    "        # get features\n",
    "        feature = final_model.predict(images, verbose=0)\n",
    "        \n",
    "        features.extend(feature)\n",
    "        \n",
    "    features=np.array(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%|          | 0/5431 [00:00<?, ?it/s]Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 119,545,856\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n",
      "100%|██████████| 5431/5431 [27:30<00:00,  3.29it/s]\n",
      "Extracted Features: 173778\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "features = extract_features_gen(image_dataframe)\n",
    "print('Extracted Features: %d' % len(features))\n",
    "RUN_FOLDER='/home/pytorch_ashish/deep_learning/data/alt_text_data_all/models/NIC_model/'\n",
    "# save to file\n",
    "dump(features, open(RUN_FOLDER+'features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173778, 4096)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sent):\n",
    "\t\n",
    "    sent = sent.lower()\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    sent =sent.replace(' x ', ' x-axis ')\n",
    "    sent=sent.replace(' y ', ' y-axis ')\n",
    "    word_tokens = word_tokenize(sent)\n",
    "    sent = ' '.join(w for w in word_tokens if not w in stop_words and len(w)>2)\n",
    "    sent= re.sub(r\"(\\d+\\s?)+\",\" number \",sent)\n",
    "\n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173778/173778 [06:40<00:00, 433.37it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(image_dataframe.shape[0])):\n",
    "    clean=clean_sentence(image_dataframe.loc[i]['alt_text'])\n",
    "    #print(clean)\n",
    "    image_dataframe['alt_text'][i]='startseq ' + clean + ' endseq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'startseq four curves graphed x-axis y-axis coordinate plane horizontal axis labeled x-axis vertical axis labeled y-axis curves labeled y-axis x-axis x number c number value different curve curve enters bottom third curve goes right enters second quadrant intersects y-axis axis enters first quadrant curve enters bottom third curve goes right enters second quadrant intersects y-axis axis enters first quadrant curve enters bottom third curve goes right passes origin enters first quadrant goes right negative curve enters bottom third curve goes right intersects negative y-axis axis negative goes right enters first quadrant curve negative curve curve curve endseq'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image_dataframe['alt_text'][0]=clean\n",
    "image_dataframe['alt_text'][12456]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173778, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataframe.to_csv('cleantext_alt_text.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Path</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "      <th>alt_text</th>\n",
       "      <th>subject_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9781337111348_11348_ch02_2.1_017-t2.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>131</td>\n",
       "      <td>181</td>\n",
       "      <td>startseq image consists minitab output visual ...</td>\n",
       "      <td>maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9781285194790_9781285194790-551-t2.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>550</td>\n",
       "      <td>593</td>\n",
       "      <td>startseq map shows second iraq war majority po...</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9781133947257_9781133947257_ch01_65-t2.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>101</td>\n",
       "      <td>184</td>\n",
       "      <td>startseq sherlock holmes mystery final solutio...</td>\n",
       "      <td>maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9781305652231_52231_ch01_f022-t2.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>24</td>\n",
       "      <td>188</td>\n",
       "      <td>startseq image consists number line numbers nu...</td>\n",
       "      <td>maths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ceng_image205.png</td>\n",
       "      <td>/home/pytorch_ashish/deep_learning/data/alt_te...</td>\n",
       "      <td>131</td>\n",
       "      <td>268</td>\n",
       "      <td>startseq image consists visual representation ...</td>\n",
       "      <td>maths</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Name  \\\n",
       "0     9781337111348_11348_ch02_2.1_017-t2.png   \n",
       "1      9781285194790_9781285194790-551-t2.png   \n",
       "2  9781133947257_9781133947257_ch01_65-t2.png   \n",
       "3        9781305652231_52231_ch01_f022-t2.png   \n",
       "4                           ceng_image205.png   \n",
       "\n",
       "                                                Path  Height  Width  \\\n",
       "0  /home/pytorch_ashish/deep_learning/data/alt_te...     131    181   \n",
       "1  /home/pytorch_ashish/deep_learning/data/alt_te...     550    593   \n",
       "2  /home/pytorch_ashish/deep_learning/data/alt_te...     101    184   \n",
       "3  /home/pytorch_ashish/deep_learning/data/alt_te...      24    188   \n",
       "4  /home/pytorch_ashish/deep_learning/data/alt_te...     131    268   \n",
       "\n",
       "                                            alt_text subject_area  \n",
       "0  startseq image consists minitab output visual ...        maths  \n",
       "1  startseq map shows second iraq war majority po...      history  \n",
       "2  startseq sherlock holmes mystery final solutio...        maths  \n",
       "3  startseq image consists number line numbers nu...        maths  \n",
       "4  startseq image consists visual representation ...        maths  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= pd.read_csv('cleantext_alt_text.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173778, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict={}\n",
    "def vocab(sent):\n",
    "    word_tokens = word_tokenize(sent)\n",
    "    for i in word_tokens:\n",
    "        try:\n",
    "            dict[i]+=1\n",
    "        except:\n",
    "            dict[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173778/173778 [01:30<00:00, 1918.80it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(test.shape[0])):\n",
    "    vocab(test.loc[i]['alt_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74489"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'startseq': 173778,\n",
       " 'image': 13773,\n",
       " 'consists': 10225,\n",
       " 'minitab': 483,\n",
       " 'output': 4824,\n",
       " 'visual': 10501,\n",
       " 'representation': 10933,\n",
       " 'columns': 4448,\n",
       " 'labeled': 127769,\n",
       " 'x-axis': 163796,\n",
       " 'y-axis': 96627,\n",
       " 'first': 31863,\n",
       " 'column': 9694,\n",
       " 'inputs': 888,\n",
       " 'second': 25592,\n",
       " 'number': 273558,\n",
       " 'endseq': 173778,\n",
       " 'map': 1916,\n",
       " 'shows': 19088,\n",
       " 'iraq': 186,\n",
       " 'war': 161,\n",
       " 'majority': 90,\n",
       " 'population': 2332,\n",
       " 'shia': 2,\n",
       " 'arab': 64,\n",
       " 'central': 2072,\n",
       " 'southeastern': 255,\n",
       " 'region': 17781,\n",
       " 'sunni': 17,\n",
       " 'southern': 878,\n",
       " 'pockets': 54,\n",
       " 'east': 1319,\n",
       " 'west': 1477,\n",
       " 'kurd': 3,\n",
       " 'north': 2794,\n",
       " 'northern': 912,\n",
       " 'path': 1156,\n",
       " 'coalition': 5,\n",
       " 'forces': 411,\n",
       " 'march': 686,\n",
       " 'april': 590,\n",
       " 'kuwait': 26,\n",
       " 'southeast': 361,\n",
       " 'baghdad': 13,\n",
       " 'triangle': 12770,\n",
       " 'tikrit': 1,\n",
       " 'top': 24143,\n",
       " 'eastern': 836,\n",
       " 'tip': 340,\n",
       " 'ramadi': 2,\n",
       " 'western': 876,\n",
       " 'oil': 783,\n",
       " 'field': 1666,\n",
       " 'lies': 889,\n",
       " 'kurdish': 19,\n",
       " 'scattered': 1125,\n",
       " 'fields': 204,\n",
       " 'regions': 2410,\n",
       " 'site': 436,\n",
       " 'major': 1045,\n",
       " 'clash': 3,\n",
       " 'iraqi': 5,\n",
       " 'insurgents': 1,\n",
       " 'baquba': 1,\n",
       " 'samara': 3,\n",
       " 'najaf': 2,\n",
       " 'karbala': 1,\n",
       " 'fallujah': 1,\n",
       " 'haditha': 1,\n",
       " 'kirkuk': 2,\n",
       " 'mosul': 3,\n",
       " 'sherlock': 1,\n",
       " 'holmes': 2,\n",
       " 'mystery': 6,\n",
       " 'final': 885,\n",
       " 'solution': 2578,\n",
       " 'moriarty': 1,\n",
       " 'mathematician': 13,\n",
       " 'wrote': 9,\n",
       " 'treatise': 1,\n",
       " 'pascal': 69,\n",
       " 'line': 111998,\n",
       " 'numbers': 4534,\n",
       " 'left': 57955,\n",
       " 'right': 89659,\n",
       " 'follows': 16303,\n",
       " 'negative': 40466,\n",
       " 'portion': 2333,\n",
       " 'placed': 2472,\n",
       " 'inside': 3897,\n",
       " 'open': 7406,\n",
       " 'bracket': 1860,\n",
       " 'caption': 3079,\n",
       " 'curve': 67980,\n",
       " 'graphed': 7351,\n",
       " 'coordinate': 11971,\n",
       " 'plane': 13476,\n",
       " 'two': 42554,\n",
       " 'points': 59805,\n",
       " 'marked': 5870,\n",
       " 'positive': 18525,\n",
       " 'axis': 117005,\n",
       " 'enters': 2865,\n",
       " 'bottom': 19043,\n",
       " 'viewing': 6426,\n",
       " 'window': 7316,\n",
       " 'third': 11876,\n",
       " 'quadrant': 53033,\n",
       " 'goes': 16379,\n",
       " 'passes': 27829,\n",
       " 'decreasing': 2773,\n",
       " 'steepness': 2594,\n",
       " 'point': 59098,\n",
       " 'slightly': 1676,\n",
       " 'increasing': 3622,\n",
       " 'exits': 2970,\n",
       " 'till': 532,\n",
       " 'shaded': 20322,\n",
       " 'boundaries': 347,\n",
       " 'vertical': 48583,\n",
       " 'lines': 24148,\n",
       " 'respectively': 6472,\n",
       " 'use': 2169,\n",
       " 'definite': 33,\n",
       " 'integral': 105,\n",
       " 'find': 857,\n",
       " 'area': 11417,\n",
       " 'bounded': 1470,\n",
       " 'graph': 99885,\n",
       " 'starts': 7682,\n",
       " 'intersects': 5134,\n",
       " 'ends': 5716,\n",
       " 'lima': 32,\n",
       " 'inner': 1302,\n",
       " 'loop': 1058,\n",
       " 'circle': 20096,\n",
       " 'polar': 1831,\n",
       " 'system': 5563,\n",
       " 'horizontal': 47384,\n",
       " 'intersect': 5085,\n",
       " 'called': 436,\n",
       " 'pole': 1607,\n",
       " 'symmetric': 648,\n",
       " 'respect': 468,\n",
       " 'centered': 5686,\n",
       " 'radius': 3339,\n",
       " 'minus': 10870,\n",
       " 'cos': 2856,\n",
       " 'theta': 1798,\n",
       " 'represented': 1685,\n",
       " 'closed': 5891,\n",
       " 'begins': 9523,\n",
       " 'axes': 3593,\n",
       " 'reaches': 2738,\n",
       " 'rightmost': 350,\n",
       " 'towards': 2052,\n",
       " 'high': 3994,\n",
       " 'leftmost': 604,\n",
       " 'low': 3305,\n",
       " 'three': 16635,\n",
       " 'intersection': 5103,\n",
       " 'fourth': 5781,\n",
       " 'passing': 18877,\n",
       " 'intersecting': 4760,\n",
       " 'exiting': 80,\n",
       " 'equation': 7011,\n",
       " 'corner': 2755,\n",
       " 'relative': 2185,\n",
       " 'maximum': 4626,\n",
       " 'crossing': 1671,\n",
       " 'minimum': 3684,\n",
       " 'year': 7101,\n",
       " 'dollars': 5009,\n",
       " 'per': 5808,\n",
       " 'euro': 42,\n",
       " 'joins': 426,\n",
       " 'origin': 18692,\n",
       " 'lunar': 38,\n",
       " 'eclipse': 70,\n",
       " 'earth': 1791,\n",
       " 'sun': 1448,\n",
       " 'moon': 443,\n",
       " 'solar': 494,\n",
       " 'hyperbola': 4535,\n",
       " 'whose': 810,\n",
       " 'vertices': 7120,\n",
       " 'focuses': 43,\n",
       " 'sqrt': 508,\n",
       " 'dotted': 5407,\n",
       " 'rectangle': 10177,\n",
       " 'shown': 4705,\n",
       " 'asymptotes': 6411,\n",
       " 'drawn': 5953,\n",
       " 'center': 10461,\n",
       " 'foci': 1392,\n",
       " 'plus': 7331,\n",
       " 'length': 10417,\n",
       " 'transverse': 740,\n",
       " 'five': 4895,\n",
       " 'curves': 14910,\n",
       " 'start': 2443,\n",
       " 'increases': 3244,\n",
       " 'steeply': 2544,\n",
       " 'exit': 346,\n",
       " 'depicts': 325,\n",
       " 'diagram': 13702,\n",
       " 'denotes': 190,\n",
       " 'atm': 42,\n",
       " 'numbered': 1418,\n",
       " 'plot': 5427,\n",
       " 'process': 1284,\n",
       " 'form': 5899,\n",
       " 'irregular': 503,\n",
       " 'coordinates': 2257,\n",
       " 'connecting': 1331,\n",
       " 'isothermal': 20,\n",
       " 'hyperbolas': 134,\n",
       " 'branches': 3315,\n",
       " 'illustration': 3918,\n",
       " 'commutative': 38,\n",
       " 'addition': 608,\n",
       " 'vectors': 2424,\n",
       " 'vector': 8730,\n",
       " 'set': 5910,\n",
       " 'triangles': 2921,\n",
       " 'formed': 2707,\n",
       " 'legs': 668,\n",
       " 'arranged': 882,\n",
       " 'head': 989,\n",
       " 'tail': 1385,\n",
       " 'fashion': 67,\n",
       " 'leg': 3125,\n",
       " 'upward': 9355,\n",
       " 'figure': 6378,\n",
       " 'rectangular': 3532,\n",
       " 'box': 6574,\n",
       " 'width': 5078,\n",
       " 'height': 6278,\n",
       " 'groups': 908,\n",
       " 'group': 2930,\n",
       " 'like': 2327,\n",
       " 'going': 2360,\n",
       " 'plotted': 8552,\n",
       " 'along': 14401,\n",
       " 'including': 1012,\n",
       " 'matrix': 1578,\n",
       " 'rows': 3726,\n",
       " 'eva': 3,\n",
       " 'ella': 2,\n",
       " 'kroner': 2,\n",
       " 'kronor': 1,\n",
       " 'rubles': 1,\n",
       " 'quadrilateral': 526,\n",
       " 'four': 9130,\n",
       " 'figures': 1059,\n",
       " 'one': 23187,\n",
       " 'act': 221,\n",
       " 'sled': 11,\n",
       " 'slipping': 3,\n",
       " 'hill': 556,\n",
       " 'makes': 867,\n",
       " 'angle': 18676,\n",
       " 'normal': 3507,\n",
       " 'force': 1149,\n",
       " 'acts': 263,\n",
       " 'gravitational': 197,\n",
       " 'downward': 7221,\n",
       " 'free': 525,\n",
       " 'body': 1552,\n",
       " 'resolved': 25,\n",
       " 'sine': 895,\n",
       " 'cosine': 602,\n",
       " 'component': 453,\n",
       " 'direction': 2521,\n",
       " 'opposite': 2847,\n",
       " 'friction': 74,\n",
       " 'parallel': 5633,\n",
       " 'bar': 7350,\n",
       " 'straight': 2485,\n",
       " 'mann': 39,\n",
       " 'whitney': 50,\n",
       " 'confidence': 899,\n",
       " 'interval': 3139,\n",
       " 'test': 3480,\n",
       " 'good': 494,\n",
       " 'median': 2249,\n",
       " 'poor': 183,\n",
       " 'estimate': 522,\n",
       " 'eta': 167,\n",
       " 'percent': 5977,\n",
       " 'less': 3423,\n",
       " 'significant': 224,\n",
       " 'wire': 584,\n",
       " 'connected': 4421,\n",
       " 'battery': 559,\n",
       " 'model': 1612,\n",
       " 'show': 1250,\n",
       " 'magnetic': 566,\n",
       " 'runs': 1594,\n",
       " 'table': 19908,\n",
       " 'six': 2804,\n",
       " 'headings': 742,\n",
       " 'springfield': 22,\n",
       " 'riverside': 13,\n",
       " 'greenfield': 10,\n",
       " 'watertown': 7,\n",
       " 'midland': 11,\n",
       " 'newhope': 8,\n",
       " 'entries': 3970,\n",
       " 'dash': 704,\n",
       " 'blank': 16222,\n",
       " 'geometric': 78,\n",
       " 'board': 381,\n",
       " 'pegs': 16,\n",
       " 'geoboard': 31,\n",
       " 'rubber': 71,\n",
       " 'bands': 215,\n",
       " 'stretched': 133,\n",
       " 'square': 9960,\n",
       " 'logic': 101,\n",
       " 'gates': 134,\n",
       " 'input': 4466,\n",
       " 'streams': 48,\n",
       " 'gate': 553,\n",
       " 'constructed': 82,\n",
       " 'stream': 293,\n",
       " 'multiple': 701,\n",
       " 'question': 628,\n",
       " 'marks': 1340,\n",
       " 'bell': 1203,\n",
       " 'shaped': 7545,\n",
       " 'cardioid': 384,\n",
       " 'screen': 10598,\n",
       " 'linreg': 110,\n",
       " 'angled': 377,\n",
       " 'made': 890,\n",
       " 'vertex': 19337,\n",
       " 'perpendicular': 2249,\n",
       " 'base': 6610,\n",
       " 'pwrreg': 6,\n",
       " 'dots': 3359,\n",
       " 'electroscope': 5,\n",
       " 'metal': 267,\n",
       " 'rods': 201,\n",
       " 'held': 152,\n",
       " 'insulating': 16,\n",
       " 'stand': 223,\n",
       " 'fixed': 385,\n",
       " 'conducting': 44,\n",
       " 'rod': 559,\n",
       " 'bent': 127,\n",
       " 'movable': 22,\n",
       " 'attached': 1094,\n",
       " 'pivot': 328,\n",
       " 'positively': 298,\n",
       " 'charged': 448,\n",
       " 'object': 760,\n",
       " 'brought': 81,\n",
       " 'close': 2522,\n",
       " 'rotates': 270,\n",
       " 'circumference': 421,\n",
       " 'diameter': 898,\n",
       " 'acting': 110,\n",
       " 'relay': 164,\n",
       " 'circuit': 1229,\n",
       " 'bulb': 264,\n",
       " 'switch': 728,\n",
       " 'current': 1257,\n",
       " 'moves': 5485,\n",
       " 'reach': 377,\n",
       " 'flows': 647,\n",
       " 'percentage': 2366,\n",
       " 'households': 229,\n",
       " 'vcrs': 1,\n",
       " 'labelled': 2525,\n",
       " 'continuing': 321,\n",
       " 'upwards': 1038,\n",
       " 'ending': 1408,\n",
       " 'illustrations': 269,\n",
       " 'rotating': 236,\n",
       " 'rotation': 642,\n",
       " 'denoted': 370,\n",
       " 'counterclockwise': 2577,\n",
       " 'arrow': 21486,\n",
       " 'around': 3493,\n",
       " 'bowling': 29,\n",
       " 'ball': 1156,\n",
       " 'cross': 2152,\n",
       " 'toward': 4957,\n",
       " 'upright': 92,\n",
       " 'pins': 61,\n",
       " 'joined': 671,\n",
       " 'pentagon': 496,\n",
       " 'another': 10464,\n",
       " 'way': 1445,\n",
       " 'arm': 341,\n",
       " 'star': 867,\n",
       " 'photo': 1233,\n",
       " 'vending': 10,\n",
       " 'machine': 413,\n",
       " 'several': 702,\n",
       " 'bottles': 87,\n",
       " 'soda': 78,\n",
       " 'drinks': 161,\n",
       " 'lined': 130,\n",
       " 'shelves': 30,\n",
       " 'screenshot': 690,\n",
       " 'database': 582,\n",
       " 'properties': 252,\n",
       " 'lower': 7415,\n",
       " 'dragged': 12,\n",
       " 'dropped': 111,\n",
       " 'shapes': 1027,\n",
       " 'menu': 411,\n",
       " 'sidebar': 8,\n",
       " 'hand': 917,\n",
       " 'side': 23390,\n",
       " 'example': 1126,\n",
       " 'type': 2009,\n",
       " 'parentheses': 1333,\n",
       " 'necessary': 122,\n",
       " 'product': 1893,\n",
       " 'changed': 109,\n",
       " 'function': 5890,\n",
       " 'parts': 4434,\n",
       " 'part': 5297,\n",
       " 'dashed': 12785,\n",
       " 'approaches': 3546,\n",
       " 'never': 397,\n",
       " 'crosses': 2750,\n",
       " 'asymptote': 11635,\n",
       " 'variable': 1333,\n",
       " 'mean': 4375,\n",
       " 'stdev': 153,\n",
       " 'minimumb': 2,\n",
       " 'rose': 343,\n",
       " 'leaves': 240,\n",
       " 'divide': 1438,\n",
       " 'leaf': 288,\n",
       " 'pieces': 494,\n",
       " 'closely': 194,\n",
       " 'next': 2914,\n",
       " 'orign': 6,\n",
       " 'cuts': 764,\n",
       " 'eight': 1256,\n",
       " 'squares': 2637,\n",
       " 'extra': 155,\n",
       " 'sign': 2386,\n",
       " 'conventions': 9,\n",
       " 'application': 186,\n",
       " 'thinlens': 1,\n",
       " 'position': 2902,\n",
       " 'time': 6092,\n",
       " 'callout': 374,\n",
       " 'increments': 23629,\n",
       " 'positions': 581,\n",
       " 'disk': 413,\n",
       " 'similar': 859,\n",
       " 'wave': 2382,\n",
       " 'approximate': 10362,\n",
       " 'data': 23539,\n",
       " 'subscript': 4130,\n",
       " 'reading': 434,\n",
       " 'multiply': 2166,\n",
       " 'value': 9842,\n",
       " 'collectively': 160,\n",
       " 'graphs': 7579,\n",
       " 'parabola': 12701,\n",
       " 'cutting': 114,\n",
       " 'x': 19257,\n",
       " 'distance': 7255,\n",
       " 'camera': 146,\n",
       " 'focused': 32,\n",
       " 'moving': 3916,\n",
       " 'lens': 317,\n",
       " 'film': 185,\n",
       " 'electronic': 241,\n",
       " 'ccd': 3,\n",
       " 'detector': 93,\n",
       " 'venn': 900,\n",
       " 'sets': 2708,\n",
       " 'excluding': 452,\n",
       " 'circles': 3382,\n",
       " 'volleyball': 25,\n",
       " 'basketball': 93,\n",
       " 'flags': 71,\n",
       " 'symbols': 723,\n",
       " 'units': 12673,\n",
       " 'hypotenuse': 3149,\n",
       " 'computing': 36,\n",
       " 'screens': 1538,\n",
       " 'wise': 266,\n",
       " 'rest': 537,\n",
       " 'additional': 665,\n",
       " 'row': 13845,\n",
       " 'entry': 1525,\n",
       " 'var': 212,\n",
       " 'stats': 190,\n",
       " 'sum': 1589,\n",
       " 'sigma': 504,\n",
       " 'pointing': 5800,\n",
       " 'sample': 3346,\n",
       " 'standard': 2868,\n",
       " 'deviation': 1068,\n",
       " 'arrangement': 302,\n",
       " 'bridges': 166,\n",
       " 'land': 731,\n",
       " 'park': 245,\n",
       " 'river': 872,\n",
       " 'natural': 540,\n",
       " 'join': 181,\n",
       " 'results': 995,\n",
       " 'select': 602,\n",
       " 'underscore': 19559,\n",
       " 'code': 3849,\n",
       " 'name': 4122,\n",
       " 'date': 1740,\n",
       " 'customer': 1117,\n",
       " 'invoice': 413,\n",
       " 'following': 13567,\n",
       " 'dune': 22,\n",
       " 'jan': 407,\n",
       " 'smith': 190,\n",
       " 'lando': 2,\n",
       " 'brian': 40,\n",
       " 'farriss': 33,\n",
       " 'selected': 1849,\n",
       " 'descript': 649,\n",
       " 'price': 3358,\n",
       " 'inovice': 1,\n",
       " 'cost': 2349,\n",
       " 'saw': 177,\n",
       " 'blade': 184,\n",
       " 'claw': 52,\n",
       " 'hammer': 114,\n",
       " 'rat': 58,\n",
       " 'file': 306,\n",
       " 'fine': 136,\n",
       " 'qpd': 18,\n",
       " 'amp': 34,\n",
       " 'cordless': 30,\n",
       " 'drill': 60,\n",
       " 'qq': 18,\n",
       " 'hrd': 16,\n",
       " 'cloth': 81,\n",
       " 'times': 5490,\n",
       " 'pwr': 18,\n",
       " 'pvc': 44,\n",
       " 'drt': 28,\n",
       " 'pipe': 336,\n",
       " 'feet': 4224,\n",
       " 'screw': 140,\n",
       " 'qty': 37,\n",
       " 'jigsaw': 55,\n",
       " 'wre': 23,\n",
       " 'hicut': 30,\n",
       " 'chain': 1011,\n",
       " 'wr': 22,\n",
       " 'tt': 29,\n",
       " 'steel': 221,\n",
       " 'matting': 25,\n",
       " 'mesh': 57,\n",
       " 'law': 511,\n",
       " 'lab': 123,\n",
       " 'assistant': 99,\n",
       " 'work': 823,\n",
       " 'scheduling': 33,\n",
       " 'sheet': 864,\n",
       " 'nine': 679,\n",
       " 'seven': 1377,\n",
       " 'monday': 208,\n",
       " 'tuesday': 163,\n",
       " 'wednesday': 194,\n",
       " 'thursday': 153,\n",
       " 'friday': 207,\n",
       " 'saturday': 119,\n",
       " 'sunday': 92,\n",
       " 'slots': 25,\n",
       " 'jones': 119,\n",
       " 'thomas': 75,\n",
       " 'gabril': 9,\n",
       " 'evans': 18,\n",
       " 'hernando': 10,\n",
       " 'jamerson': 4,\n",
       " 'chung': 7,\n",
       " 'tabrin': 10,\n",
       " 'mustava': 9,\n",
       " 'womack': 5,\n",
       " 'vann': 6,\n",
       " 'dalton': 19,\n",
       " 'rommel': 6,\n",
       " 'hernandez': 10,\n",
       " 'porter': 8,\n",
       " 'troyana': 5,\n",
       " 'antony': 5,\n",
       " 'willis': 18,\n",
       " 'morris': 10,\n",
       " 'kallen': 12,\n",
       " 'trayana': 1,\n",
       " 'highlon': 3,\n",
       " 'rostav': 5,\n",
       " 'inum': 1,\n",
       " 'batey': 4,\n",
       " 'kadin': 6,\n",
       " 'avery': 8,\n",
       " 'sorals': 10,\n",
       " 'winston': 8,\n",
       " 'aaron': 44,\n",
       " 'witte': 6,\n",
       " 'casey': 13,\n",
       " 'thompson': 7,\n",
       " 'karpov': 2,\n",
       " 'crow': 94,\n",
       " 'foot': 663,\n",
       " 'relationships': 167,\n",
       " 'professor': 150,\n",
       " 'student': 594,\n",
       " 'entities': 121,\n",
       " 'zero': 1976,\n",
       " 'many': 1376,\n",
       " 'relationship': 860,\n",
       " 'advises': 8,\n",
       " 'non': 645,\n",
       " 'identifiable': 21,\n",
       " 'attributes': 581,\n",
       " 'entity': 401,\n",
       " 'primary': 679,\n",
       " 'key': 1437,\n",
       " 'essential': 183,\n",
       " 'specialty': 35,\n",
       " 'rank': 199,\n",
       " 'email': 195,\n",
       " 'attribute': 153,\n",
       " 'initial': 3826,\n",
       " 'foreign': 327,\n",
       " 'pressure': 1509,\n",
       " 'captions': 80,\n",
       " 'pairs': 966,\n",
       " 'digits': 480,\n",
       " 'divided': 5972,\n",
       " 'ones': 774,\n",
       " 'fours': 46,\n",
       " 'sixteens': 19,\n",
       " 'maintaining': 55,\n",
       " 'respective': 489,\n",
       " 'symbol': 1213,\n",
       " 'unit': 4672,\n",
       " 'carried': 146,\n",
       " 'add': 1591,\n",
       " 'numerals': 104,\n",
       " 'write': 869,\n",
       " 'carry': 168,\n",
       " 'thefours': 1,\n",
       " 'fourwrite': 4,\n",
       " 'bring': 655,\n",
       " 'russia': 472,\n",
       " 'cuba': 102,\n",
       " 'anode': 100,\n",
       " 'assembly': 522,\n",
       " 'cathode': 59,\n",
       " 'vacuum': 114,\n",
       " 'covered': 345,\n",
       " 'envelope': 84,\n",
       " 'housing': 302,\n",
       " 'filled': 651,\n",
       " 'house': 637,\n",
       " 'electron': 455,\n",
       " 'beam': 513,\n",
       " 'emerged': 5,\n",
       " 'focus': 2171,\n",
       " 'radiation': 196,\n",
       " 'occurs': 479,\n",
       " 'save': 136,\n",
       " 'option': 646,\n",
       " 'ribbon': 123,\n",
       " 'mouse': 64,\n",
       " 'pointer': 121,\n",
       " 'th': 1077,\n",
       " 'ellipse': 4186,\n",
       " 'paper': 536,\n",
       " 'minor': 373,\n",
       " 'clockwise': 2586,\n",
       " 'enter': 740,\n",
       " 'marriages': 53,\n",
       " 'thousand': 1015,\n",
       " 'almost': 531,\n",
       " 'frictionless': 9,\n",
       " 'ramp': 193,\n",
       " 'meters': 1508,\n",
       " 'falls': 9814,\n",
       " 'represents': 6809,\n",
       " 'hours': 2389,\n",
       " 'thousands': 2303,\n",
       " 'near': 4605,\n",
       " 'bosch': 18,\n",
       " 'injection': 190,\n",
       " 'pump': 495,\n",
       " 'rack': 39,\n",
       " 'various': 801,\n",
       " 'components': 743,\n",
       " 'drive': 563,\n",
       " 'camshaft': 74,\n",
       " 'fuel': 1319,\n",
       " 'control': 1335,\n",
       " 'short': 851,\n",
       " 'ring': 1482,\n",
       " 'actuator': 64,\n",
       " 'speed': 1554,\n",
       " 'sensor': 780,\n",
       " 'circus': 8,\n",
       " 'performers': 10,\n",
       " 'performer': 26,\n",
       " 'standing': 299,\n",
       " 'raised': 235,\n",
       " 'platform': 92,\n",
       " 'throwing': 17,\n",
       " 'apple': 149,\n",
       " 'twenty': 401,\n",
       " 'degrees': 4748,\n",
       " 'corresponding': 1611,\n",
       " 'reads': 4622,\n",
       " 'ground': 1101,\n",
       " 'blindfolded': 3,\n",
       " 'basket': 46,\n",
       " 'm': 940,\n",
       " 'end': 11548,\n",
       " 'mark': 1672,\n",
       " 'rhombus': 198,\n",
       " 'decreases': 1996,\n",
       " 'without': 776,\n",
       " 'touching': 589,\n",
       " 'infinite': 234,\n",
       " 'therefore': 236,\n",
       " 'improper': 64,\n",
       " 'diverges': 43,\n",
       " 'unbounded': 72,\n",
       " 'given': 3976,\n",
       " 'values': 14955,\n",
       " 'age': 2616,\n",
       " 'lamar': 2,\n",
       " 'district': 155,\n",
       " 'nez': 6,\n",
       " 'perce': 6,\n",
       " 'firehole': 2,\n",
       " 'total': 4544,\n",
       " 'calf': 14,\n",
       " 'yearling': 2,\n",
       " 'adult': 222,\n",
       " 'oscillating': 832,\n",
       " 'sin': 3359,\n",
       " 'pi': 584,\n",
       " 'amplitude': 1210,\n",
       " 'period': 2667,\n",
       " 'oscillation': 123,\n",
       " 'fairly': 94,\n",
       " 'emf': 209,\n",
       " 'devices': 118,\n",
       " 'resistor': 464,\n",
       " 'potential': 534,\n",
       " 'difference': 1800,\n",
       " 'red': 4493,\n",
       " 'lead': 704,\n",
       " 'terminal': 5159,\n",
       " 'black': 1670,\n",
       " 'spiral': 371,\n",
       " 'polygons': 78,\n",
       " 'hexagon': 557,\n",
       " 'regular': 435,\n",
       " 'polygon': 813,\n",
       " 'midpoint': 1005,\n",
       " 'absolute': 1149,\n",
       " 'convergence': 38,\n",
       " 'either': 1377,\n",
       " 'divergence': 8,\n",
       " 'double': 2442,\n",
       " 'sided': 1109,\n",
       " 'text': 3262,\n",
       " 'series': 1653,\n",
       " 'may': 1299,\n",
       " 'converge': 96,\n",
       " 'diverge': 15,\n",
       " 'endpoints': 1043,\n",
       " 'compound': 210,\n",
       " 'shannon': 5,\n",
       " 'monique': 5,\n",
       " 'jacob': 14,\n",
       " 'justin': 8,\n",
       " 'cheung': 4,\n",
       " 'victor': 29,\n",
       " 'extended': 449,\n",
       " 'meets': 1386,\n",
       " 'rule': 450,\n",
       " 'gives': 450,\n",
       " 'particle': 593,\n",
       " 'greater': 2222,\n",
       " 'limited': 119,\n",
       " 'mutually': 53,\n",
       " 'exclusive': 46,\n",
       " 'universal': 543,\n",
       " 'alpha': 995,\n",
       " 'kept': 137,\n",
       " 'orange': 1554,\n",
       " 'juice': 119,\n",
       " 'shape': 3545,\n",
       " 'cuboid': 124,\n",
       " 'centimeters': 1130,\n",
       " 'breadth': 170,\n",
       " 'step': 2542,\n",
       " 'wedge': 294,\n",
       " 'radiographic': 22,\n",
       " 'exposing': 15,\n",
       " 'penetrometer': 1,\n",
       " 'ray': 4828,\n",
       " 'plots': 1715,\n",
       " 'light': 3037,\n",
       " 'transmitted': 45,\n",
       " 'versus': 1896,\n",
       " 'exposure': 163,\n",
       " 'log': 2027,\n",
       " 'scale': 1986,\n",
       " 'remains': 349,\n",
       " 'constant': 1093,\n",
       " 'inscribed': 291,\n",
       " 'euler': 104,\n",
       " 'concentric': 564,\n",
       " 'circular': 1360,\n",
       " 'outer': 1417,\n",
       " 'rhombi': 4,\n",
       " 'parallelogram': 805,\n",
       " 'quadrilaterals': 65,\n",
       " 'measurements': 225,\n",
       " 'stationary': 78,\n",
       " 'observers': 16,\n",
       " 'helicopter': 55,\n",
       " 'observer': 188,\n",
       " 'rel': 21,\n",
       " 'multiplied': 362,\n",
       " 'velocity': 879,\n",
       " 'measures': 2136,\n",
       " 'moved': 277,\n",
       " 'away': 3087,\n",
       " 'branched': 89,\n",
       " 'cycloid': 68,\n",
       " 'tangent': 2814,\n",
       " 'branch': 6323,\n",
       " 'touch': 582,\n",
       " 'cycloids': 6,\n",
       " 'touches': 1093,\n",
       " 'trigonometric': 42,\n",
       " 'inverse': 949,\n",
       " 'whisker': 660,\n",
       " 'segment': 9374,\n",
       " 'within': 2982,\n",
       " 'quartile': 553,\n",
       " 'search': 132,\n",
       " 'searched': 6,\n",
       " 'flourless': 1,\n",
       " 'chocolate': 220,\n",
       " 'cake': 132,\n",
       " 'recipe': 39,\n",
       " 'written': 888,\n",
       " 'advanced': 93,\n",
       " 'named': 297,\n",
       " 'directrix': 1147,\n",
       " 'adjacent': 2259,\n",
       " 'rectangles': 2956,\n",
       " 'equal': 6940,\n",
       " 'defined': 360,\n",
       " 'mid': 1021,\n",
       " 'chart': 2985,\n",
       " 'mass': 1282,\n",
       " 'energy': 1441,\n",
       " 'particles': 474,\n",
       " 'fusion': 139,\n",
       " 'individual': 394,\n",
       " 'energies': 77,\n",
       " 'bars': 2642,\n",
       " 'c': 1790,\n",
       " 'earlier': 43,\n",
       " 'tall': 288,\n",
       " 'shorter': 423,\n",
       " 'depicted': 219,\n",
       " 'deficit': 69,\n",
       " 'discontinuous': 59,\n",
       " 'caterpillar': 39,\n",
       " 'processing': 151,\n",
       " 'cycle': 911,\n",
       " 'buffers': 12,\n",
       " 'clutch': 293,\n",
       " 'cruise': 45,\n",
       " 'resume': 46,\n",
       " 'brake': 103,\n",
       " 'algorithm': 97,\n",
       " 'located': 1689,\n",
       " 'conversion': 185,\n",
       " 'electronics': 65,\n",
       " 'coolant': 130,\n",
       " 'temperature': 1991,\n",
       " 'boost': 38,\n",
       " 'throttle': 112,\n",
       " 'vehicle': 314,\n",
       " 'also': 3970,\n",
       " 'power': 2291,\n",
       " 'sense': 113,\n",
       " 'filter': 339,\n",
       " 'engine': 616,\n",
       " 'timing': 87,\n",
       " 'delay': 56,\n",
       " 'detect': 28,\n",
       " 'duration': 211,\n",
       " 'cylinder': 1161,\n",
       " 'multiplexer': 2,\n",
       " 'enable': 66,\n",
       " 'diagnostic': 84,\n",
       " 'lamp': 105,\n",
       " 'link': 145,\n",
       " 'retarder': 4,\n",
       " 'coming': 390,\n",
       " 'parametric': 99,\n",
       " 'equations': 1081,\n",
       " 'opening': 9870,\n",
       " 'cone': 1232,\n",
       " 'invnorm': 6,\n",
       " 'concave': 6351,\n",
       " 'centers': 285,\n",
       " 'yards': 371,\n",
       " 'starting': 2423,\n",
       " 'fitted': 308,\n",
       " 'standardized': 120,\n",
       " 'residual': 1203,\n",
       " 'leaved': 55,\n",
       " 'thetas': 14,\n",
       " 'inverted': 1272,\n",
       " 'equilateral': 378,\n",
       " 'solid': 6088,\n",
       " 'reflecting': 78,\n",
       " 'surface': 4324,\n",
       " 'debt': 267,\n",
       " 'lightbulb': 13,\n",
       " 'man': 1065,\n",
       " 'carries': 84,\n",
       " 'tree': 1504,\n",
       " 'mountain': 376,\n",
       " 'equivalent': 477,\n",
       " 'arrowed': 95,\n",
       " 'masses': 97,\n",
       " 'suspended': 107,\n",
       " 'fiber': 164,\n",
       " 'middle': 3459,\n",
       " 'sides': 7388,\n",
       " 'source': 1031,\n",
       " 'incident': 151,\n",
       " 'mirror': 623,\n",
       " 'reflected': 552,\n",
       " 'y': 3732,\n",
       " 'replace': 461,\n",
       " 'catalog': 18,\n",
       " 'degree': 2240,\n",
       " 'delvar': 1,\n",
       " 'dependask': 1,\n",
       " 'dependauto': 1,\n",
       " 'det': 88,\n",
       " 'diagnosticoff': 1,\n",
       " 'diagnosticon': 3,\n",
       " 'remaining': 816,\n",
       " 'tool': 201,\n",
       " 'toolbar': 63,\n",
       " 'opens': 1656,\n",
       " 'dialog': 857,\n",
       " 'pane': 234,\n",
       " 'drops': 302,\n",
       " 'stencils': 22,\n",
       " 'quick': 116,\n",
       " 'notation': 1256,\n",
       " 'options': 886,\n",
       " 'separator': 54,\n",
       " 'working': 371,\n",
       " 'rowed': 56,\n",
       " 'course': 307,\n",
       " 'title': 940,\n",
       " 'description': 546,\n",
       " 'years': 4869,\n",
       " 'aids': 117,\n",
       " 'cases': 463,\n",
       " 'millions': 2393,\n",
       " 'fifth': 1818,\n",
       " 'sixth': 1035,\n",
       " 'seventh': 557,\n",
       " 'lists': 1852,\n",
       " 'largest': 662,\n",
       " 'average': 2835,\n",
       " 'upper': 7558,\n",
       " 'symmetry': 1500,\n",
       " 'cube': 951,\n",
       " 'grid': 1575,\n",
       " 'faces': 411,\n",
       " 'face': 1006,\n",
       " 'representing': 2431,\n",
       " 'begin': 966,\n",
       " 'proton': 98,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary= set(dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74489"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173778, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= test.loc[:,:]\n",
    "y= test.loc[:,'subject_area']\n",
    "X_train=X[0:130333]\n",
    "X_test=X[130333:]\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130333, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43445, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130333/130333 [00:28<00:00, 4565.71it/s]\n"
     ]
    }
   ],
   "source": [
    "all_alt_text = list()\n",
    "for i in tqdm(range(X_train.shape[0])):\n",
    "    all_alt_text.append(X_train.loc[i]['alt_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43445/43445 [00:09<00:00, 4610.37it/s]\n"
     ]
    }
   ],
   "source": [
    "test_all_alt_text = list()\n",
    "for i in tqdm(range(X_test.shape[0])):\n",
    "    test_all_alt_text.append(X_test.loc[i]['alt_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130333 43445\n"
     ]
    }
   ],
   "source": [
    "print(len(all_alt_text), len(test_all_alt_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52413"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_alt_text)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename='features.pkl'\n",
    "infile = open(filename,'rb')\n",
    "photo_features = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173778, 4096)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return self.it.__next__()\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@threadsafe_generator\n",
    "def data_generator(batch_size,tokenizer, vocab_size, photo_features, all_alt_text):\n",
    "    global generator_index\n",
    "    print(\"Generator Initiated\", generator_index)\n",
    "    generator_index+=1\n",
    "    while True:\t\t\n",
    "        num_samples = len(all_alt_text)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            photo = photo_features[offset : offset + batch_size]\n",
    "            alt_text = all_alt_text[offset : offset + batch_size]\n",
    "            print(\" \",offset, \" I am offset of Generator index \",generator_index)\n",
    "            \n",
    "            X1, X2, y = list(), list(), list()\n",
    "            for j in range(len(alt_text)):\n",
    "                seq = tokenizer.texts_to_sequences([alt_text[j]])[0]\n",
    "                \n",
    "                for i in range(1, len(seq)):\n",
    "                    in_seq, out_seq =seq[:i], seq[i]\n",
    "                    \n",
    "                    in_seq = pad_sequences([in_seq], maxlen=200)[0]   #200 = max_length\n",
    "                    # encode output sequence\n",
    "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "                    \n",
    "                    X1.append(photo[j])\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "                    \n",
    "                    \n",
    "            #in_img, in_seq, out_word = create_sequences(tokenizer, vocab_size, photo, alt_text)\n",
    "            yield [array(X1), array(X2)], array(y)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "class Data_Gen(Sequence):\n",
    "    '''Generates Data for Keras'''\n",
    "    def __init__(self, batch_size, tokenizer, vocab_size, photo_features, alt_text):\n",
    "        '''Initialization'''\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab_size = vocab_size\n",
    "        self.photo_features = photo_features\n",
    "        self.alt_text = alt_text\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):           #Must be implemented for every Sequence Item\n",
    "        '''Denotes the no of batches per epoch'''\n",
    "        return int(np.floor(self.photo_features.shape[0]/self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):       #Must be implemented for every Sequence Item and it should return a complete Batch\n",
    "        '''Generate one batch of data'''\n",
    "        # Generate indexes of the batch\n",
    "        #indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]   #indexes is not present in the Main Sequence Keras Class\n",
    "        photo = self.photo_features[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        alt_text = self.alt_text[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        X1, X2, y = list(), list(), list()\n",
    "        for j in range(len(alt_text)):\n",
    "            seq = tokenizer.texts_to_sequences([alt_text[j]])[0]\n",
    "\n",
    "            for i in range(1, len(seq)):\n",
    "                in_seq, out_seq =seq[:i], seq[i]\n",
    "\n",
    "                in_seq = pad_sequences([in_seq], maxlen=200)[0]   #200 = max_length\n",
    "                # encode output sequence\n",
    "                out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "\n",
    "                X1.append(photo[j])\n",
    "                X2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "\n",
    "\n",
    "        #in_img, in_seq, out_word = create_sequences(tokenizer, vocab_size, photo, alt_text)\n",
    "        return [array(X1), array(X2)], array(y)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Create a generator that iterate over the Sequence.\"\"\"\n",
    "        for item in (self[i] for i in range(len(self))):\n",
    "            yield item\n",
    "\n",
    "    \n",
    "    #def on_epoch_end(self):                           Optional function can be used to do shuffling\n",
    "     #   'Updates indexes after each epoch'\n",
    "      #  self.indexes = np.arange(len(self.list_IDs))\n",
    "       # if self.shuffle == True:\n",
    "        #    np.random.shuffle(self.indexes)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130333, 4096) (43445, 4096)\n"
     ]
    }
   ],
   "source": [
    "train_photo_features=photo_features[0:130333]\n",
    "test_photo_features=photo_features[130333:]\n",
    "print(train_photo_features.shape, test_photo_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index= [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4072"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(int(np.floor(train_photo_features.shape[0]/32)))\n",
    "np.arange(len(self.list_IDs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "global generator_index\n",
    "generator_index =-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Data_Gen' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-34530c4e3b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_Gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_photo_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_alt_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Data_Gen' object is not an iterator"
     ]
    }
   ],
   "source": [
    "batch_size=3\n",
    "generator = Data_Gen(batch_size, tokenizer, vocab_size, train_photo_features, all_alt_text)\n",
    "inputs, outputs = next(generator)\n",
    "print(inputs[0].shape)\n",
    "print(inputs[1].shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 4096)\n",
      "(89, 200)\n",
      "(89, 52413)\n"
     ]
    }
   ],
   "source": [
    "#global test_generator_index\n",
    "#test_generator_index=0\n",
    "batch_size=3\n",
    "#test_generator = data_generator(batch_size, tokenizer, vocab_size, test_photo_features, test_all_alt_text)\n",
    "test_inputs, test_outputs = next(test_generator)\n",
    "print(test_inputs[0].shape)\n",
    "print(test_inputs[1].shape)\n",
    "print(test_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "108\n",
      "120\n",
      "150\n",
      "283\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "#print(len(tokenizer.texts_to_sequences([all_alt_text[0]])[0])-1)\n",
    "#print(len(tokenizer.texts_to_sequences([all_alt_text[0]])[0])+len(tokenizer.texts_to_sequences([all_alt_text[1]])[0])-2)\n",
    "print(len(tokenizer.texts_to_sequences([all_alt_text[0]])[0])+len(tokenizer.texts_to_sequences([all_alt_text[1]])[0])+len(tokenizer.texts_to_sequences([all_alt_text[2]])[0]) -3)\n",
    "print(len(tokenizer.texts_to_sequences([all_alt_text[3]])[0])+len(tokenizer.texts_to_sequences([all_alt_text[4]])[0])+len(tokenizer.texts_to_sequences([all_alt_text[5]])[0]) -3)\n",
    "print(len(tokenizer.texts_to_sequences([all_alt_text[6]])[0])+len(tokenizer.texts_to_sequences([all_alt_text[7]])[0])+len(tokenizer.texts_to_sequences([all_alt_text[8]])[0]) -3)\n",
    "print(len(tokenizer.texts_to_sequences([all_alt_text[9]])[0])+len(tokenizer.texts_to_sequences([all_alt_text[10]])[0])+len(tokenizer.texts_to_sequences([all_alt_text[11]])[0]) -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "56\n",
      "74\n",
      "104\n",
      "80\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "#print(len(tokenizer.texts_to_sequences([test_all_alt_text[0]])[0])-1)\n",
    "#print(len(tokenizer.texts_to_sequences([test_all_alt_text[0]])[0])+len(tokenizer.texts_to_sequences([test_all_alt_text[1]])[0])-2)\n",
    "print(len(tokenizer.texts_to_sequences([test_all_alt_text[0]])[0])+len(tokenizer.texts_to_sequences([test_all_alt_text[1]])[0])+len(tokenizer.texts_to_sequences([test_all_alt_text[2]])[0]) -3)\n",
    "print(len(tokenizer.texts_to_sequences([test_all_alt_text[3]])[0])+len(tokenizer.texts_to_sequences([test_all_alt_text[4]])[0])+len(tokenizer.texts_to_sequences([test_all_alt_text[5]])[0]) -3)\n",
    "print(len(tokenizer.texts_to_sequences([test_all_alt_text[6]])[0])+len(tokenizer.texts_to_sequences([test_all_alt_text[7]])[0])+len(tokenizer.texts_to_sequences([test_all_alt_text[8]])[0]) -3)\n",
    "print(len(tokenizer.texts_to_sequences([test_all_alt_text[9]])[0])+len(tokenizer.texts_to_sequences([test_all_alt_text[10]])[0])+len(tokenizer.texts_to_sequences([test_all_alt_text[11]])[0]) -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def define_model(vocab_size, max_length):\n",
    "\t# feature extractor model\n",
    "\tinputs1 = Input(shape=(4096,))\n",
    "\tfe1 = Dropout(0.5)(inputs1)\n",
    "\tfe2 = Dense(25, activation='relu')(fe1)       #256\n",
    "\t# sequence model\n",
    "\tinputs2 = Input(shape=(max_length,))\n",
    "\tse1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "\tse2 = Dropout(0.5)(se1)\n",
    "\tse3 = LSTM(25)(se2)                           #256\n",
    "\t# decoder model\n",
    "\tdecoder1 = add([fe2, se3])\n",
    "\tdecoder2 = Dense(25, activation='relu')(decoder1)           #256\n",
    "\toutputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\t# tie it together [image, seq] [word]\n",
    "\tmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\t# summarize model\n",
    "\tmodel.summary()\n",
    "\tplot_model(model, to_file='model.png', show_shapes=True)\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 4096)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 200, 256)     13417728    input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 4096)         0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 200, 256)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 25)           102425      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 25)           28200       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 25)           0           dense_6[0][0]                    \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 25)           650         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 52413)        1362738     dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 14,911,741\n",
      "Trainable params: 14,911,741\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "max_length=200\n",
    "vocab_size= 52413\n",
    "model = define_model(vocab_size, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 52413 200 (130333, 4096) 300\n"
     ]
    }
   ],
   "source": [
    "print(batch_size, vocab_size, max_length, train_photo_features.shape, len(all_alt_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, TerminateOnNaN, TensorBoard, EarlyStopping\n",
    "import os\n",
    "from datetime import datetime\n",
    "RUN_FOLDER='/home/pytorch_ashish/deep_learning/data/alt_text_data_all/models/NIC_model/'\n",
    "logdir = os.path.join(RUN_FOLDER, \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
    "\n",
    "#checkpoint_filepath=os.path.join(run_folder, \"model.h5\")\n",
    "checkpoint1 = ModelCheckpoint(os.path.join(RUN_FOLDER, \"caption_model.h5\"), monitor='loss',  save_best_only=True, verbose=1, mode= 'min')\n",
    "checkpoint2 = ModelCheckpoint(os.path.join(RUN_FOLDER, 'caption_weights.h5'), save_weights_only = True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=1, mode='min', verbose=1)\n",
    "EarlyStop = EarlyStopping(monitor='loss', min_delta=0.001, patience=31, verbose=1, mode='min', restore_best_weights=True)\n",
    "terminate = TerminateOnNaN()\n",
    "\n",
    "\n",
    "callbacks_list = [checkpoint1, checkpoint2, reduce_lr, tensorboard_callback, EarlyStop, terminate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130333\n",
      "43445\n"
     ]
    }
   ],
   "source": [
    "NUM_IMAGES = train_photo_features.shape[0]\n",
    "print(NUM_IMAGES)\n",
    "TEST_NUM_IMAGES = test_photo_features.shape[0]\n",
    "print(TEST_NUM_IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96 samples, validate on 89 samples\n",
      "96/96 - 5s - loss: 10.7925 - val_loss: 10.3645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb808080a58>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([inputs[0], inputs[1]], outputs, epochs=1, verbose=2, validation_data=([test_inputs[0], test_inputs[1]], test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "train_photo_features=train_photo_features[0:300]\n",
    "NUM_IMAGES = train_photo_features.shape[0]\n",
    "#print(NUM_IMAGES)\n",
    "all_alt_text= all_alt_text[0:300]\n",
    "#print(len(all_alt_text))\n",
    "generator = data_generator(batch_size, tokenizer, vocab_size, train_photo_features, all_alt_text)\n",
    "\n",
    "test_photo_features=test_photo_features[0:300]\n",
    "TEST_NUM_IMAGES = test_photo_features.shape[0]\n",
    "#print(TEST_NUM_IMAGES)\n",
    "test_all_alt_text=test_all_alt_text[0:300]\n",
    "#print(len(test_all_alt_text))\n",
    "batch_size=16\n",
    "test_generator = data_generator(batch_size, tokenizer, vocab_size, test_photo_features, test_all_alt_text)\n",
    "\n",
    "global generator_index\n",
    "generator_index =-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  16  I am offset of Generator index  0\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "Train for 18.75 steps\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-40:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 970, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/data_utils.py\", line 962, in pool_fn\n",
      "    initargs=(seqs, self.random_seed, get_worker_id_queue()))\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 174, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 239, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/popen_fork.py\", line 66, in _launch\n",
      "    self.pid = os.fork()\n",
      "OSError: [Errno 12] Cannot allocate memory\n",
      "\n",
      "Process Keras_worker_ForkPoolWorker-19:\n",
      "Process Keras_worker_ForkPoolWorker-18:\n",
      "Process Keras_worker_ForkPoolWorker-21:\n",
      "Process Keras_worker_ForkPoolWorker-20:\n",
      "Process Keras_worker_ForkPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x = generator\n",
    "    , shuffle = False\n",
    "    , epochs = 100\n",
    "    , initial_epoch = 0\n",
    "    , callbacks = callbacks_list\n",
    "    , steps_per_epoch = NUM_IMAGES / batch_size\n",
    "    , workers = 1\n",
    "    , use_multiprocessing = True\n",
    "    #, validation_data= test_generator\n",
    "    #, validation_steps= TEST_NUM_IMAGES / batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Initiated -1\n",
      "  0  I am offset of Generator index  0\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the `tf.data.Dataset`.\n",
      "Train for 18.75 steps\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "  16  I am offset of Generator index  0\n",
      "  16  I am offset of Generator index  0\n",
      "  16  I am offset of Generator index  0\n",
      "  32  I am offset of Generator index  0\n",
      "  32  I am offset of Generator index  0\n",
      "  32  I am offset of Generator index  0\n",
      "  48  I am offset of Generator index  0\n",
      "  48  I am offset of Generator index  0\n",
      "  48  I am offset of Generator index  0\n",
      " 1/18 [>.............................] - ETA: 2:57 - loss: 10.8665  64  I am offset of Generator index  0\n",
      "  64  I am offset of Generator index  0\n",
      "  64  I am offset of Generator index  0\n",
      " 2/18 [==>...........................] - ETA: 1:40 - loss: 10.8552  80  I am offset of Generator index  0\n",
      " 3/18 [===>..........................] - ETA: 1:10 - loss: 10.8383  80  I am offset of Generator index  0\n",
      " 4/18 [=====>........................] - ETA: 53s - loss: 10.8238   80  I am offset of Generator index  0\n",
      " 5/18 [=======>......................] - ETA: 42s - loss: 10.7976  96  I am offset of Generator index  0\n",
      " 6/18 [========>.....................] - ETA: 34s - loss: 10.7601  96  I am offset of Generator index  0\n",
      " 7/18 [==========>...................] - ETA: 28s - loss: 10.7199  96  I am offset of Generator index  0\n",
      " 8/18 [===========>..................] - ETA: 23s - loss: 10.6658  112  I am offset of Generator index  0\n",
      " 9/18 [=============>................] - ETA: 19s - loss: 10.5968  112  I am offset of Generator index  0\n",
      "10/18 [===============>..............] - ETA: 16s - loss: 10.4829  112  I am offset of Generator index  0\n",
      "11/18 [================>.............] - ETA: 13s - loss: 10.3535  128  I am offset of Generator index  0\n",
      "12/18 [==================>...........] - ETA: 11s - loss: 10.2065  128  I am offset of Generator index  0\n",
      "  128  I am offset of Generator index  0\n",
      "13/18 [===================>..........] - ETA: 9s - loss: 10.1898   144  I am offset of Generator index  0\n",
      "  144  I am offset of Generator index  0\n",
      "14/18 [=====================>........] - ETA: 7s - loss: 10.1566  144  I am offset of Generator index  0\n",
      "  160  I am offset of Generator index  0\n",
      "15/18 [=======================>......] - ETA: 6s - loss: 10.1076  160  I am offset of Generator index  0\n",
      "16/18 [========================>.....] - ETA: 4s - loss: 9.9379   160  I am offset of Generator index  0\n",
      "17/18 [==========================>...] - ETA: 2s - loss: 9.7634  176  I am offset of Generator index  0\n",
      "18/18 [===========================>..] - ETA: 1s - loss: 9.5869  176  I am offset of Generator index  0\n",
      "  176  I am offset of Generator index  0\n",
      "\n",
      "Epoch 00001: loss improved from inf to 9.45942, saving model to /home/pytorch_ashish/deep_learning/data/alt_text_data_all/models/NIC_model/caption_model.h5\n",
      "  192  I am offset of Generator index  0\n",
      "  192  I am offset of Generator index  0\n",
      "  192  I am offset of Generator index  0\n",
      "\n",
      "Epoch 00001: saving model to /home/pytorch_ashish/deep_learning/data/alt_text_data_all/models/NIC_model/caption_weights.h5\n",
      "  208  I am offset of Generator index  0\n",
      "  208  I am offset of Generator index  0\n",
      "19/18 [==============================] - 30s 2s/step - loss: 9.4451\n",
      "  208  I am offset of Generator index  0\n",
      "Epoch 2/100\n",
      " 1/18 [>.............................] - ETA: 11s - loss: 6.6395  224  I am offset of Generator index  0\n",
      " 2/18 [==>...........................] - ETA: 12s - loss: 6.5442  224  I am offset of Generator index  0\n",
      " 3/18 [===>..........................] - ETA: 12s - loss: 6.5388  224  I am offset of Generator index  0\n",
      "  240  I am offset of Generator index  0\n",
      " 4/18 [=====>........................] - ETA: 13s - loss: 6.5261  240  I am offset of Generator index  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-3:\n",
      "Process Keras_worker_ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "Process Keras_worker_ForkPoolWorker-2:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 347, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 341, in put\n",
      "    obj = _ForkingPickler.dumps(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/reduction.py\", line 51, in dumps\n",
      "    cls(buf, protocol).dump(obj)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/18 [=======>......................] - ETA: 12s - loss: 6.5261\n",
      "Epoch 00002: loss improved from 9.45942 to 6.52323, saving model to /home/pytorch_ashish/deep_learning/data/alt_text_data_all/models/NIC_model/caption_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 463, in _handle_results\n",
      "    task = get()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 251, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "_pickle.UnpicklingError: invalid load key, '\\xbb'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: saving model to /home/pytorch_ashish/deep_learning/data/alt_text_data_all/models/NIC_model/caption_weights.h5\n",
      " 5/18 [=======>......................] - ETA: 17s - loss: 6.5261"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-0c8d73ebe734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_IMAGES\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#, validation_data= test_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#, validation_steps= TEST_NUM_IMAGES / batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Keras_worker_ForkPoolWorker-4:\n",
      "Process Keras_worker_ForkPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "Process Keras_worker_ForkPoolWorker-5:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 347, in put\n",
      "    self._writer.send_bytes(obj)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 398, in _send_bytes\n",
      "    self._send(buf)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
      "    put((job, i, result))\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
      "    with self._wlock:\n",
      "  File \"/opt/conda/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x = generator\n",
    "    , shuffle = False\n",
    "    , epochs = 100\n",
    "    , initial_epoch = 0\n",
    "    , callbacks = callbacks_list\n",
    "    , steps_per_epoch = NUM_IMAGES / batch_size\n",
    "    , workers = 3\n",
    "    , use_multiprocessing = False\n",
    "    #, validation_data= test_generator\n",
    "    #, validation_steps= TEST_NUM_IMAGES / batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pytorch_ashish/deep_learning/data/alt_text_data_all/models/NIC_model'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
